{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from json import dump, load\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Clean Transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'ANNOUNCER','BIDEN', 'WARREN', 'SANDERS', 'HARRIS', 'YANG', 'BOOKER',\n",
    "           'Oâ€™ROURKE', 'KLOBUCHAR', 'CASTRO', 'STEPHANOPOULOS', 'RAMOS', 'DAVIS',\n",
    "           'MUIR', 'BUTTIGIEG'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_transcript(transcript_file, headers, include_comment=False):\n",
    "    \"\"\"\n",
    "    Clean the ABC transcript. This function saves cleaned transcript and a list\n",
    "    (in json format), where each entry is the speaker of the corresponding line\n",
    "    in the transcript.\n",
    "    \n",
    "    Args:\n",
    "        transcript_file(string): path to the transcript file (txt format)\n",
    "        headers([string]): a list of speakers\n",
    "        include_comment(bool): whether to include comment such as (APPLAUSE)\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    file_prefix = re.sub(r'(.+)\\.txt', r'\\1', transcript_file)\n",
    "    \n",
    "    cleaned_transcript = ''\n",
    "    speakers = []\n",
    "    cur_speaker = ''\n",
    "\n",
    "    with open(transcript_file, 'r') as fp:\n",
    "        for line in fp:\n",
    "            line = line.replace('\\n', '')\n",
    "\n",
    "            if line == '':\n",
    "                continue\n",
    "\n",
    "            # If ignore comment\n",
    "            if not include_comment and '(' in line:\n",
    "                continue\n",
    "\n",
    "            for header in headers:\n",
    "                if header + ':' in line:\n",
    "                    cur_speaker = header\n",
    "                    line = line.replace(header + ': ', '')\n",
    "                    break\n",
    "\n",
    "            cleaned_transcript += line + '\\n'\n",
    "            speakers.append(cur_speaker)\n",
    "\n",
    "    # Output the cleaned transcript and speaker information\n",
    "    with open(file_prefix + '_cleaned.txt', 'w') as fp:\n",
    "        fp.write(cleaned_transcript)\n",
    "\n",
    "    dump(speakers, open(file_prefix + '_cleaned.json', 'w'),\n",
    "         ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_transcript('full.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Audio Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Sentencify Transcript\n",
    "\n",
    "We want to put each sentence as one row for the transcript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sentenced_transcript = []\n",
    "sentenced_speaker = []\n",
    "\n",
    "speaker_list = load(open('./full_cleaned.json', 'r'))\n",
    "\n",
    "def switch_special(line, hide):\n",
    "    special_chars = ['...', 'U.S.', 'p.m.', 'U.N.', 'D.A.', 'D.C.', 'Mr.', '.com']\n",
    "    special_masks = ['+++', 'U+S+', 'p+m+', 'U+N+', 'D+A+', 'D+C+', 'Mr+', '+com']\n",
    "    temp = line\n",
    "\n",
    "    if hide:\n",
    "        for i in range(len(special_chars)):\n",
    "            if special_chars[i] in line:\n",
    "                temp = temp.replace(special_chars[i], special_masks[i])\n",
    "    else:\n",
    "        if '+' in line:\n",
    "            temp = temp.replace('+', '.')\n",
    "\n",
    "    return temp\n",
    "            \n",
    "\n",
    "with open('./full_cleaned.txt', 'r') as fp:\n",
    "    lines = fp.readlines()\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        has_three_dots = False\n",
    "        has_usa = False\n",
    "        cur_line = lines[i]\n",
    "        cur_speaker = speaker_list[i]\n",
    "        \n",
    "        cur_line = switch_special(cur_line, True)\n",
    "\n",
    "        while '.' in cur_line or '?' in cur_line:\n",
    "            dot_index = cur_line.find('.' if '.' in cur_line else '?')\n",
    "\n",
    "            # Skip number\n",
    "            if cur_line[dot_index + 1].isdigit():\n",
    "                temp_list = list(cur_line)\n",
    "                temp_list[dot_index] = '+'\n",
    "                cur_line = ''.join(temp_list)\n",
    "                continue\n",
    "            # Include ending quote\n",
    "            if cur_line[dot_index + 1] == '\"':\n",
    "                dot_index += 1\n",
    "            if cur_line[dot_index + 1: dot_index + 3] == '\\'\"':\n",
    "                dot_index += 2\n",
    "                    \n",
    "            cur_sentense = cur_line[:dot_index + 1]\n",
    "            cur_sentense = switch_special(cur_sentense, False)\n",
    "            sentenced_transcript.append(cur_sentense)\n",
    "            sentenced_speaker.append(cur_speaker)\n",
    "\n",
    "            cur_line = cur_line[dot_index+1:]\n",
    "            if cur_line[0] == ' ':\n",
    "                cur_line = cur_line[1:]\n",
    "            if cur_line == '\\n':\n",
    "                cur_line = ' '\n",
    "            if cur_line[0] == '.':\n",
    "                pass\n",
    "                # print(lines[i])\n",
    "\n",
    "        if not cur_line.isspace():\n",
    "            cur_line = switch_special(cur_line, False)\n",
    "            sentenced_transcript.append(cur_line)\n",
    "            sentenced_speaker.append(cur_speaker)\n",
    "\n",
    "leters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
    "for i in range(len(sentenced_transcript)):\n",
    "    if sentenced_transcript[i][0] not in leters and sentenced_transcript[i][0:3] != '...':\n",
    "        print(sentenced_transcript[i-2])\n",
    "        print(sentenced_transcript[i-1])\n",
    "        print(sentenced_transcript[i])\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'sentense': sentenced_transcript,\n",
    "                   'speaker': sentenced_speaker})\n",
    "df.to_csv('full_sentence.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
